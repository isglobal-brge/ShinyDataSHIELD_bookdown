% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={ShinyDataSHIELD User's Guide},
  pdfauthor={Escribà Montagut, Xavier; González, Juan R.},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{ShinyDataSHIELD User's Guide}
\author{Escribà Montagut, Xavier; González, Juan R.}
\date{2021-07-19}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{overview}{%
\chapter{Overview}\label{overview}}

\includegraphics[width=0.5\textwidth,height=\textheight]{images/ds_logo.png}

ShinyDataSHIELD is a non-disclosive data analysis toolbox powered by DataSHIELD with the following features:

\begin{itemize}
\tightlist
\item
  Descriptive statistics: Summary, scatter plots, histograms and heatmaps of table variables.
\item
  Statistic models: GLM and GLMer model fittings
\item
  Omic analysis: GWAS, LIMMA, \ldots{} using different types of resources (VCF files, PLINK, RSE, eSets)
\end{itemize}

The features available on ShinyDataSHIELD are powered by different packages of the DataSHIELD project (dsBaseClient and dsOmicsClient), it uses them in a seamless way so the final user of ShinyDataSHIELD can perform all the included studies without writing a single line of code and get all the resulting figures and tables by the click of a button.

\hypertarget{setup}{%
\chapter{Setup}\label{setup}}

In this section, a list of all the R packages required to launch ShinyDataSHIELD is given. Following it, two methodologies to install them is provided. The recommended methodology is to install all the packages using R and launch the Shiny app from there. However, depending on the version of R and other variables that can't be contemplated on a case to case basis, the user might have problems installing the R packages, if that is the case, an alternative has been created using Docker.

\hypertarget{r-packages}{%
\section{R packages}\label{r-packages}}

The packages that contain the main functionalities of ShinyDataSHIELD are the following.

\begin{itemize}
\tightlist
\item
  \href{https://github.com/datashield/DSI}{DSI}: The DataSHIELD Interface (DSI) handles the connections to the databases.
\item
  \href{https://github.com/datashield/DSOpal}{DSOpal}: DSOpal is an extension of DSI to connecto to Opal servers.
\item
  \href{https://github.com/datashield/dsBaseClient}{dsBaseClient}: Implementation of the base package R functions to obtain non-disclosive returns from the Opal servers (Example: Base package function \texttt{as.factor} is implemented as \texttt{ds.asFactor}).
\item
  \href{https://github.com/isglobal-brge/dsOmicsClient}{dsOmicsClient}: Functions to perform non-disclosive omic analysis using BioConductor packages on the Opal servers.
\end{itemize}

On the following table, all the packages required by ShinyDataSHIELD are shown along the versions used during development.

\begin{longtable}[]{@{}ll@{}}
\toprule
Package & Version \\
\midrule
\endhead
DSI & 1.1.0 \\
DSOpal & 1.1.0 \\
dsBaseClient & 6.0.1 \\
dsOmicsClient & 1.0.0 \\
shinydashboard & 0.7.1 \\
shiny & 1.4.0.2 \\
shinyalert & 1.1 \\
DT & 0.13 \\
data.table & 1.12.8 \\
shinyjs & 1.1 \\
shinyBS & 0.61 \\
shinycssloaders & 0.3 \\
shinyWidgets & 0.5.4 \\
stringr & 1.4.0 \\
\bottomrule
\end{longtable}

\hypertarget{install}{%
\section{Install}\label{install}}

\hypertarget{install-required-packages-with-r}{%
\subsection{Install required packages with R}\label{install-required-packages-with-r}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.00}}@{}}
\toprule
❗ Observation 1 \\
\midrule
\endhead
The previous methodology has been tested on a clean installation of R 4.0.3 and RStudio 1.3, if any errors occur please consider using a clean install or refer to the official R documentation regarding the errors you are getting. Also, there is a \href{https://github.com/RcppCore/Rcpp/issues/1105}{known bug} when using R 4.0.0 and Shiny, install R 4.0.3 or higher to solve it. \\
\bottomrule
\end{longtable}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.00}}@{}}
\toprule
❗ Observation 2 \\
\midrule
\endhead
Please note that if you are using a Linux machine, the library \texttt{libxml2} needs to be installed before trying to install the R packages, on a Ubuntu distribution it can be installed with \texttt{sudo\ apt-get\ install\ libxml2}, for other distributions please refer to the official documentation of it. \\
\bottomrule
\end{longtable}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.00}}@{}}
\toprule
❗ Observation 3 \\
\midrule
\endhead
In order to install everything from RStudio, developer tools are needed. Since they are not downloaded by default with R or RStudio, please make sure to install them. On Windows machines \href{https://cran.r-project.org/bin/windows/Rtools/}{Rtools} needs to be installed (just install it, there is no need of performing the second step of the link `Putting Rtools on the PATH'), for Linux machines make sure the library \emph{make} is installed, for Ubuntu distributions it can be installed by running \texttt{sudo\ apt-get\ install\ build-essential} on a bash terminal, for other distributions please refer to the official documentation of it. \\
\bottomrule
\end{longtable}

In order to install the packages, an R console is needed. The simplest way to get it is to install \href{https://cloud.r-project.org/}{R} and \href{https://rstudio.com/products/rstudio/download/}{RStudio}, launch RStudio and start typing commands to the R console.

\begin{figure}
\centering
\includegraphics{images/setup1.png}
\caption{RStudio console}
\end{figure}

To install the required packages input the following commands to the console:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Install devtools}
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"devtools"}\NormalTok{)}

\CommentTok{\# Install required packages to run ShinyDataSHIELD}
\NormalTok{devtools}\SpecialCharTok{::}\FunctionTok{source\_url}\NormalTok{(}\StringTok{"https://raw.githubusercontent.com/isglobal{-}brge/ShinyDataSHIELD/master/installer.R"}\NormalTok{)}

\CommentTok{\# Install ShinyDataSHIELD}
\NormalTok{devtools}\SpecialCharTok{::}\FunctionTok{install\_github}\NormalTok{(}\StringTok{"isglobal{-}brge/ShinyDataSHIELD"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The previous commands will install a library called \texttt{devtools} that is needed to source online scripts and run them. The next line sources a file that installs all the required packages to run ShinyDataSHIELD, finally the package that contains the Shiny application itself is installed.

\hypertarget{run-the-shiny-app}{%
\subsubsection{Run the Shiny app}\label{run-the-shiny-app}}

Once all the packages are installed, ShinyDataSHIELD can be executed inputing the following command on the R console, which will launch the application on a new window.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Run ShinyDataSHIELD}
\NormalTok{ShinyDataSHIELD}\SpecialCharTok{::}\FunctionTok{app}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{install-with-docker}{%
\subsection{Install with Docker}\label{install-with-docker}}

Another option to use ShinyDataSHIELD is to install it using Docker. Docker can be installed on a Linux / Mac OS X machine without any complications as any other application, on Windows systems however it can be a little bit more troubling, there are many online resources to help. Please refer to the following links to \href{https://docs.docker.com/docker-for-windows/install-windows-home/}{install Docker on Windows Home}, to \href{https://blog.nillsf.com/index.php/2020/02/17/setting-up-wsl2-windows-terminal-and-oh-my-zsh/}{setup the Linux Windows Subsystem and terminal} and to \href{https://docs.docker.com/docker-for-windows/wsl/}{execute Docker on Windows}.

Once Docker is up and running, execute the following command on a bash terminal (make sure Docker is running, if not search for the \texttt{Docker\ Desktop} app and launch it) to download and launch ShinyDataSHIELD. Be aware that the Docker images weights \textasciitilde{} 1.5 GB, so if your internet connection is slow it may take a while.

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{docker}\NormalTok{ run }\AttributeTok{{-}{-}rm} \AttributeTok{{-}p}\NormalTok{ 80:80 brgelab/shiny{-}data{-}shield}
\end{Highlighting}
\end{Shaded}

The container will be exposed on the local port 80 and it will render on that port the application itself, so to start using ShinyDataSHIELD open your web browser of choice and go to the site

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{localhost:80}
\end{Highlighting}
\end{Shaded}

At the beginning it may take some time for the application to render, this is because all the needed R libraries are being loaded, to be sure the container is actually working, take a look at the terminal where you inputed the Docker command, there you will see all the R verbose stating the libraries are being loaded.

Once the user has finished using ShinyDataSHIELD, the container needs to be stopped to avoid wasting CPU resources, to do so, input the following command on a bash terminal (the command needs to be inputed on a new bash window):

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{docker}\NormalTok{ container ls}
\end{Highlighting}
\end{Shaded}

This will prompt all the running containers, find the one with the NAMES \texttt{brgelab/shiny-data-shield} and copy it's CONTAINER ID, then input the following bash command:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{docker}\NormalTok{ stop xxxxxxxxxxxx}
\end{Highlighting}
\end{Shaded}

Where xxxxxxxxxxxx is the CONTAINER ID.

To run the application again, just enter the first bash command (\texttt{docker\ run\ -\/-rm\ -p\ 80:80\ brgelab/shiny-data-shield}), since it has already been downloaded, the application is cached on the computer and it will launch straight away. If the user wants to remove the Docker image from the computer, input the following bash command:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{docker}\NormalTok{ image rm brgelab/exposome{-}shiny}
\end{Highlighting}
\end{Shaded}

If the user wants to download the actual source code of the Shiny, install all the required packages and launch it locally on it's machine, feel free to download it \href{https://github.com/isglobal-brge/dsOmicsShiny}{from Github}. There's a script called \texttt{installer.R} at the root of the repository with a short installer of all the required packages. Please note that the installer script may fail depending on the R version and others, for that reason is advised to always run the Docker version of ShinyDataSHIELD, as it only requires a single terminal command and will work no matter what.

\hypertarget{functionalities}{%
\chapter{Functionalities}\label{functionalities}}

Along this section, an overview of the functionalities implemented on ShinyDataSHIELD is given. There's information about how to use the funcionalities as well as some limitations or constraints to take into account when using ShinyDataSHIELD.

\hypertarget{data-entry}{%
\section{Data entry}\label{data-entry}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.00}}@{}}
\toprule
⚠️ DISCLAIMER \\
\midrule
\endhead
Along this section the terms \textbf{table} and \textbf{resource} are widely used, it is important noting that when the autor talks about a table, it refers to what is shown as a table on the Opal server. A resource that holds a table is called (and treated) as a resource. \\
\bottomrule
\end{longtable}

The first step to any analysis is to load the required tables or resources to the study server(s). To do so, the user has to provide the server URL and the login credentials. This will allow the application to connect to the OPAL server and retrieve all the projects and resources / tables from them. Afterwards, the user can select the desired resources / tables and load them to the study servers.

It is very important to understand the difference between a server (OPAL server) and a study server (R instances running inside an OPAL server), a study server can be visualized as an R session that has some tables and resources loaded. For that reason we can have multiple study servers on a single OPAL server, which is indeed needed when performing pooled studies.

To properly explain how to load the desired study servers for multiple types of analysis, let's do a guided tour of the interface.

Since Opal 4.2 there is a new concept introduced called \texttt{profiles} which correspond to different R servers (\href{https://rockdoc.obiba.org/en/latest/}{rockr}). The user can choose which profile to use for each study server (more info \protect\hyperlink{profiles}{here}).

\begin{figure}

{\centering \includegraphics[width=12.71in]{images/data_entry1} 

}

\caption{Connect to server, initial state}\label{fig:dataentry1}
\end{figure}

On Figure \ref{fig:dataentry1} the initial state of the \emph{Connect to server} tab is shown, here we can see some credentials are already inputted, which correspond to a demo server. There is the option of performing a login to the server via traditional user/pass or using personal access token {[}PAT{]}.

\begin{figure}

{\centering \includegraphics[width=12.71in]{images/data_entry2} 

}

\caption{Connect to server, selecting tables and resources}\label{fig:dataentry2}
\end{figure}

Once connected to the server, the interface is actualized showing the available projects that contain tables inside. To show the projects that contain resources, just click on the \emph{Table} toggle. An example is illustrated on Figure \ref{fig:dataentry2}.

If we want to get further information from a table(s) or resource(s), select them and click on the \emph{Further information of selection}, this will open the OPAL UI on a browser and will display the associated page for the selected items. If more than one item is selected, a page for each one will be opened. An example of this functionality is shown on the Figure \ref{fig:dataentry3} where a table was selected to retrieve further information.

\begin{figure}

{\centering \includegraphics[width=17.49in]{images/data_entry3} 

}

\caption{OPAL UI with information from a table}\label{fig:dataentry3}
\end{figure}

Knowing which items are of our interest, we can add them to be loaded on the study servers, to do that select the items and click \emph{Add selected item(s)}. A new table will appear underneath showing everything selected, illustrated on Figure \ref{fig:dataentry4}. On this table all the elements from all the servers will be added to have the general picture of what will be available on the study servers.

\begin{figure}

{\centering \includegraphics[width=12.68in]{images/data_entry4} 

}

\caption{Connect to server, selected items}\label{fig:dataentry4}
\end{figure}

Reached this point, let's see different use cases and how we have to configure the application for them.

\hypertarget{single-resource-table-approach}{%
\subsection{Single resource / table approach}\label{single-resource-table-approach}}

Not much to say about this, just select it and click the \emph{Connect} button.

\begin{figure}

{\centering \includegraphics[width=12.68in]{images/data_entry5} 

}

\caption{Connect to server. Single resource / table approach}\label{fig:dataentry5}
\end{figure}

\hypertarget{multiple-resource-study}{%
\subsection{Multiple resource study}\label{multiple-resource-study}}

Some studies require to put more than one resource on a single study server, this is the case of using VCF files to perform a GWAS; they require two resources, the VCF resource and the covariates resource (which is a resource that holds a plain table). For this use case, the user has to select the multiple resources from the dropdown inputs, add them to a single study and connect to it. Two important things must be said for this use case, 1) By default the tables/resources from one server are added to the same study server; 2) to have tables/resources on the same study server, they have to be from the same server, this translates to: we can't put a table from server X and a resource from server Y on the same study server.

\begin{figure}

{\centering \includegraphics[width=12.68in]{images/data_entry6} 

}

\caption{Connect to server. Single resource / table approach}\label{fig:dataentry6}
\end{figure}

\hypertarget{pooled-data-from-the-same-server}{%
\subsection{Pooled data from the same server}\label{pooled-data-from-the-same-server}}

It is not uncommon that the same OPAL server has multiple tables that we wish to analyze using a pooled approach. To perform this kind of analysis we have to select all the tables (they have to consistent column-wise to be pooled). The important thing to take into account is that the tables need to be on different study servers in order to be analyzed using a pooled approach, in order to achieve that the user has to double click on the cells in order to edit them (Figure \ref{fig:dataentry7}). There are a couple of rules regarding the naming of the study servers, 1) User inputted names can't be of the format \texttt{StudyX} (where X is a number), and 2) Similarly to what has been stated before, items from different servers can't be on the same study server.

\begin{figure}

{\centering \includegraphics[width=12.67in]{images/data_entry7} 

}

\caption{Connect to server. Study server edit}\label{fig:dataentry7}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=12.68in]{images/data_entry8} 

}

\caption{Connect to server. Pooled data from the same server approach}\label{fig:dataentry8}
\end{figure}

\hypertarget{pooled-data-from-different-servers}{%
\subsection{Pooled data from different servers}\label{pooled-data-from-different-servers}}

When pooling data from different servers, we have to separately login to all of them. On the upper part of the interface there is a \emph{+} symbol used to add a new server (Figure \ref{fig:dataentry9}), when clicking the \emph{-} symbol the last server added will be removed from the interface. The procedure is exactly the same as what we've already seen, the only difference is that on the table of selected items, we will now see items from different servers (Figure \ref{fig:dataentry10}). Since by default items from different servers are added to different study servers, there is no need to manually configure that.

\begin{figure}

{\centering \includegraphics[width=12.68in]{images/data_entry9} 

}

\caption{Connect to server. New server}\label{fig:dataentry9}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=12.68in]{images/data_entry10} 

}

\caption{Connect to server. Pooled data from different servers approach}\label{fig:dataentry10}
\end{figure}

\hypertarget{profiles}{%
\subsection{Study server profiles}\label{profiles}}

Extracted from the \href{https://opaldoc.obiba.org/en/latest/admin/rserver.html}{official documentation}: ``A DataSHIELD profile is a R server profile combined with a DataSHIELD configuration (allowed functions, options and permissions). DataSHIELD users can then decide in which environment their analysis are to be performed, for a better reproducible science.''. On the opal-demo site, there is a different array of profiles, illustrated on the Figure \ref{fig:opal-profiles}.

\begin{figure}

{\centering \includegraphics[width=29.14in]{images/opal-datashield-profiles} 

}

\caption{Opal demo profiles. Extracted from https://opaldoc.obiba.org/}\label{fig:opal-profiles}
\end{figure}

In ShinyDataSHIELD, there is the option of assigning the required profile to each study server, there is only one requirement to be taken into account: A study server can only have one distinct profile. So the configuration table of Figure \ref{fig:opal-profiles1} is valid, and the configuration table of Figure \ref{fig:opal-profiles2} will yield a connection error (Figure \ref{fig:opal-profiles3}).

\begin{figure}

{\centering \includegraphics[width=13.81in]{images/opal-datashield-profiles1} 

}

\caption{Correct profiles configuration}\label{fig:opal-profiles1}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=13.81in]{images/opal-datashield-profiles2} 

}

\caption{Incorrect profiles configuration}\label{fig:opal-profiles2}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=13.81in]{images/opal-datashield-profiles3} 

}

\caption{Incorrect profiles configuration error message}\label{fig:opal-profiles3}
\end{figure}

\hypertarget{table-column-types}{%
\section{Table column types}\label{table-column-types}}

⚠️ TABLES USED TO DEMO THIS SECTION

From https://opal-demo.obiba.org/ :

STUDY

TABLE

PROFILE

Study1a

CNSIM.CNSIM1

default

Study1b

CNSIM.CNSIM2

default

Study1c

CNSIM.CNSIM3

default

The table column types functionality is available for tables as well as the following resource types:

\begin{itemize}
\tightlist
\item
  SQL tables
\item
  Tidy data files (tables): \texttt{*.csv}, \texttt{*.tsv}, etc
\end{itemize}

All of the above options will be shown on the table that shows the available tables to use on this module. As stated on the use cases, to perform a pooled analysis the tables have to be on different study servers. Column integrity is checked before allowing the user the access to the other tabs.

The function of this module is to get information about the class of each column of a table.

\begin{figure}

{\centering \includegraphics[width=12.67in]{images/table_columns_1} 

}

\caption{Classes of the CNSIM table}\label{fig:tableclass1}
\end{figure}

Aside from that, there's the option of changing the class of a column. This transformation is done using the proper DataSHIELD functions that perform disclosive checks before allowing the transformation. This is specially important for transformation from numeric to factor for example.

The allowed classes to perform transformations are:

\begin{itemize}
\tightlist
\item
  Character
\item
  Numeric
\item
  Factor
\end{itemize}

To perform a class change, double click on the desired row and and a drop-down menu will appear, choose the new class and click `Confirm', after the checks, the table will be updated to display the new class.

\begin{figure}

{\centering \includegraphics[width=12.67in]{images/table_columns_2} 

}

\caption{Class change}\label{fig:tableclass2}
\end{figure}

Integer could be added if it was of interest. Please \href{https://github.com/isglobal-brge/ShinyDataSHIELD/issues}{file an issue on GitHub} if that is the case.

\hypertarget{descriptive-statistics}{%
\section{Descriptive statistics}\label{descriptive-statistics}}

⚠️ TABLES USED TO DEMO THIS SECTION

From https://opal-demo.obiba.org/ :

STUDY

TABLE

PROFILE

Study1a

CNSIM.CNSIM1

default

Study1b

CNSIM.CNSIM2

default

Study1c

CNSIM.CNSIM3

default

The descriptive statistics functionality is available for tables as well as the following resource types:

\begin{itemize}
\tightlist
\item
  SQL tables
\item
  Tidy data files (tables): \texttt{*.csv}, \texttt{*.tsv}, etc
\end{itemize}

All of the above options will be shown on the table that shows the available tables to use on this module. As stated on the use cases, to perform a pooled analysis the tables have to be on different study servers. Column integrity is checked before allowing the user the access to the other tabs.

When using pooled data the descriptive statistics is by default of the pooled data, however, the graphical visualizations included on descriptive statistics provide the option of showing separated plots for the different studies.

\hypertarget{summary}{%
\subsection{Summary}\label{summary}}

The summary provides non-disclosive insights on the different variables of the loaded data. This functionality is only available for factors and numeric variables, only variables that meet this criteria will be on the selector. When the desired summary is disclosive no table will be shown (as the function call returns an Error stating that the the return is disclosive).

When the selected variable is a factor, the output shown is a count of all the different factors. It can be visualized with the pooled data or divided by study servers.

\includegraphics{images/descriptive_stats1.png}

\includegraphics{images/descriptive_stats1_2.png}

When the selected variable is numerical, the output shown is a quantiles and mean table. It can be visualized with the pooled data or divided by study servers.

\includegraphics{images/descriptive_stats2.png}

\includegraphics{images/descriptive_stats2_2.png}

\hypertarget{scatter-plot}{%
\subsection{Scatter plot}\label{scatter-plot}}

Create a non-disclosive scatter plot by selecting two numerical variables (one for each axis). This type of plot can only be generated using numerical variables, for that reason variables that do not meet this criteria are not shown on the selector. It can be visualized with the pooled data or divided by study servers.

\includegraphics{images/descriptive_stats3.png}

\includegraphics{images/descriptive_stats3_2.png}

\hypertarget{histogram}{%
\subsection{Histogram}\label{histogram}}

Create a non-disclosive histogram of a selected variable. This type of plot can only be generated using numerical variables, for that reason variables that do not meet this criteria are not shown on the selector. It can be visualized with the pooled data or divided by study servers.

\includegraphics{images/descriptive_stats4.png}

\includegraphics{images/descriptive_stats4_2.png}

\hypertarget{heatmap}{%
\subsection{Heatmap}\label{heatmap}}

Create a non-disclosive heatmap plot by selecting two numerical variables (one for each axis). This type of plot can only be generated using numerical variables, for that reason variables that do not meet this criteria are not shown on the selector. It can be visualized with the pooled data or divided by study servers.

\includegraphics{images/descriptive_stats5.png}

\includegraphics{images/descriptive_stats5_2.png}

\hypertarget{boxplot}{%
\subsection{Boxplot}\label{boxplot}}

Create a non-disclosive Boxplot by selecting as many numerical variables as desired. This plot has the option of performing groupings using one or two factor variables from the same table. It can be visualized with the pooled data or divided by study servers.

\includegraphics{images/descriptive_stats6.png}

\includegraphics{images/descriptive_stats6_2.png}

\includegraphics{images/descriptive_stats6_3.png}

\includegraphics{images/descriptive_stats6_4.png}

The Boxplot functionality uses \texttt{ggplot2}; a novel in-app editor named \texttt{ggEditLite} has been introduced inside the Shiny application to allow simple graphic modifications of the plot to adapt it to the style of choice, add title, subtitle, etc. This feature will be rolled out to all the plots as they get upgraded to make use of the \texttt{ggplot2} package.

\includegraphics{images/descriptive_stats6_5.png}

\hypertarget{statistic-models}{%
\section{Statistic models}\label{statistic-models}}

⚠️ TABLES USED TO DEMO THIS SECTION

From https://opal-demo.obiba.org/ :

GLM and mixed models

STUDY

TABLE

PROFILE

Study1a

CNSIM.CNSIM1

default

Study1b

CNSIM.CNSIM2

default

Study1c

CNSIM.CNSIM3

default

Survival analysis

STUDY

TABLE

PROFILE

Study1a

SURVIVAL.EXPAND\_WITH\_MISSING1

survival

Study1b

SURVIVAL.EXPAND\_WITH\_MISSING2

survival

Study1c

SURVIVAL.EXPAND\_WITH\_MISSING3

survival

Statistic models are available for tables as well as the following resource types:

\begin{itemize}
\tightlist
\item
  SQL tables
\item
  Tidy data files (tables): \texttt{*.csv}, \texttt{*.tsv}, etc
\end{itemize}

There are three different statisticals models available to fit, GLM models (Statistics models tab), GLMer models (Mixed statistical models tab) and Survival cox models (Survival analysis tab).

\hypertarget{glm-models}{%
\subsection{GLM models}\label{glm-models}}

The tab to fit a non-disclosive generalized linear models (GLM) contains a box to manually input the formula, a selector for the output family and a table displaying the variables of the data and the type of each variable. There is finally the option to perform a pooled analysis or a meta-study. The possible output families are:

\begin{itemize}
\tightlist
\item
  Gaussian
\item
  Poisson
\item
  Binomial
\end{itemize}

There's some help built into ShinyDataSHIELD regarding how to write the GLM formula, which is prompted to the user when clicking on the ``Formula input help'' button. The display of the variables can be toggled on and off for the convenience of use.

Once the GLM model is fitted a table below the variables display will be rendered with the model results. The download button will prompt a system window to select where to store the shown table, it will save it as a \texttt{*.csv}.

When using pooled data, the results of the GLM model will be of the combined data.

(To do: Display more information of why a model fitment fails)

\includegraphics{images/stat_models1.png}

When using a meta-study approach the results correpond to the betas and standard errors for three different meta study methodologies:

\begin{itemize}
\tightlist
\item
  Maximum Likelihood
\item
  REstricted Maximum Likelihood
\item
  Fixed-Effects meta-analysis
\end{itemize}

This three methodologies can be visualized on a forest plot by selecting the desired one.

\includegraphics{images/stat_models1_2.png}

\hypertarget{mixed-models}{%
\subsection{Mixed models}\label{mixed-models}}

The tab to fit non-disclosive generalized mixed effects models (GLMer) contains a box to manually input the formula, a selector for the output family and a table displaying the variables of the data and the type of each variable. The possible output families are:

\begin{itemize}
\tightlist
\item
  Poisson
\item
  Binomial
\end{itemize}

There's some help built into ShinyDataSHIELD regarding how to write the GLMer formula, which is prompted to the user when clicking on the ``Formula input help'' button. The display of the variables can be toggled on and off for the convenience of use.

Once the GLMer model is fitted a table below the variables display will be rendered displaying the results. The download button will prompt a system window to select where to store the shown table, it will save them as a \texttt{*.csv}.

The mixed model results are independent for each study server. There's a selector to toggle between the results of the different study servers.

(To do: Display more information of why a model fitment fails)

\includegraphics{images/stat_models2.png}

\hypertarget{survival-analysis}{%
\subsection{Survival Analysis}\label{survival-analysis}}

The tab to fit non-disclosive survival analysis is divided into four different subtabs. The first subtab, is used to create a survival object (See the information about \texttt{survival::Surv} function for more information \url{https://www.rdocumentation.org/packages/survival/versions/2.11-4/topics/Surv}). To create this object, three columns from the selected tables are needed and a parameter:

(Information about each column copied from the \texttt{survival::Surv} function documentation)

\begin{itemize}
\tightlist
\item
  Start time variable: for right censored data, this is the follow up time. For interval data, the first argument is the starting time for the interval.
\item
  End time variable: ending time of the interval for interval censored or counting process data only. Intervals are assumed to be open on the left and closed on the right, \texttt{(start,\ end{]}}. For counting process data, event indicates whether an event occurred at the end of the interval.
\item
  Event variable: The status indicator, normally 0=alive, 1=dead. Other choices are \texttt{TRUE/FALSE} (\texttt{TRUE} = death) or 1/2 (2=death). For interval censored data, the status indicator is 0=right censored, 1=event at \texttt{time} (Start time variable), 2=left censored, 3=interval censored. For multiple enpoint data the event variable will be a factor, whose first level is treated as censoring. Although unusual, the event indicator can be omitted, in which case all subjects are assumed to have an event.
\item
  Type of censoring (parameter): character string specifying the type of censoring. Possible values are ``\texttt{right}'', ``\texttt{left}'', ``\texttt{counting}'', ``\texttt{interval}'', ``\texttt{interval2}'' or ``\texttt{mstate}''.
\end{itemize}

For the data used on this demo, the columns are the following:

\begin{itemize}
\tightlist
\item
  Start time variable: \texttt{starttime}
\item
  End time variable: \texttt{endtime}
\item
  Event variable: \texttt{cens}
\item
  Type of censoring (parameter): \texttt{counting}
\end{itemize}

We have to make sure all three columns are numeric on this demo:

\includegraphics{images/survival2.png}

\includegraphics{images/survival3.png}

Once the survival object is created, the tab `Fit survival model' is unlocked. On this tab, as with the other statistic models, there is a help button and a `Toggle variables tables' to visualize the variables available to construct the model. The formula has the following structure:

\texttt{survival\_object\textasciitilde{}tables\_sm\$variable+tables\_sm\$variable2}

Where \texttt{survival\_object} and \texttt{tables\_sm} can't be modified. An example model for this demo data would be:

\texttt{survival\_object\textasciitilde{}tables\_sm\$age+tables\_sm\$female}

\includegraphics{images/survival4.png}

If a model is fitted, the left two tabs can be accessed, this two tabs correspond to two possible visualization options of the survival analysis. The `Meta analysis' plots a forestplot of a selected model variable using different meta-analysis methods. The `Visualization of model' plots the survival curves for each study server.

\includegraphics{images/survival5.png}

\includegraphics{images/survival6.png}

\hypertarget{genomics}{%
\section{Genomics}\label{genomics}}

⚠️ RESOURCES USED TO DEMO THIS SECTION

From https://opal-demo.obiba.org/ :

Analysis with BioConductor

STUDY

RESOURCE

PROFILE

Study1

RSRC.brge

omics

Study1

RSRC.brge\_vcf

omics

Analysis with PLINK

STUDY

RESOURCE

PROFILE

Study1

RSRC.brge\_plink

omics

Inside the genomics tab of dsOmicshiny there are two subtabs, one to perform analysis using BioConductor methods and another to perform analysis using PLINK methods.

\hypertarget{analysis-with-bioconductor}{%
\subsection{Analysis with BioConductor}\label{analysis-with-bioconductor}}

To perform non-disclosive genomic analysis using BioConductor methodologies, the user has to input a VCF resource with a covariates resource (table) on the same study.

When performing this kind of analysis, as explained on the Data Entry section, only one study server can be used.

The Analysis with BioConductor has two sub-tabs, the first one corresponds to the GWAS, and as the name implies is used to perform a GWAS (Genome wide association study) non-disclosive analysis on the loaded data. There is a selector for the condition and the covariates to adjusted for. The fitted model is: snp \textasciitilde{} condition + covar1 + \ldots{} + covarN. The results of the model appear on a table below the selectors. The download button will prompt a system window to select where to store the shown table, it will save it as a \texttt{*.csv}. The second subtab is to display a Manhattan plot of the GWAS results. The dowload plot button saves the shown figure as a \texttt{*.png}.

\includegraphics{images/genomics1.png}

\includegraphics{images/genomics2.png}

\hypertarget{analysis-with-plink}{%
\subsection{Analysis with PLINK}\label{analysis-with-plink}}

To perform non-disclosive analysis using \href{http://zzz.bwh.harvard.edu/plink/index.shtml}{PLINK} commands, the user has to load a SSH resource. The tab contains a field to input the PLINK command and a brief memo stating that when inputing the PLINK command to run there is no need of inputting it as \texttt{plink\ ...} as would be done on a terminal interface, the user has to input just the \texttt{...}; also, there is no need to put \texttt{–out} to indicate the output file.

Once the command is run, a table with the results is displayed under the command input, the download button will prompt a system window to select where to store the shown table, it will save them as a \texttt{*.csv}. A button to display the raw terminal output appears to display the user on a popup the plain text.

\includegraphics{images/genomics3.png}

\includegraphics{images/genomics4.png}

There's also a sub-tab to show a Manhattan plot with the results obtained. The dowload plot button saves the shown figure as a \texttt{*.png}.

\includegraphics{images/genomics5.png}

\hypertarget{omics}{%
\section{Omics}\label{omics}}

⚠️ RESOURCES USED TO DEMO THIS SECTION

From https://opal-demo.obiba.org/ :

LIMMA

STUDY

RESOURCE

PROFILE

Study1

RSRC.GSE80970

omics

DESeq and edge R: To be determined

On the Omics tab there are three different subtabs for different methodologies to perform non-disclosive analysis: limma, DESeq and edgeR. The resources that can be used are ExpressionSets and RangegSummarizedExperiments. If the resources are pooled the user has to input each one in a different study on the data entry.

\hypertarget{limma}{%
\subsection{LIMMA}\label{limma}}

The limma non-disclosive analysis tab contains two selectors to select the condition and covariables of the analysis (resulting formula is: feature \textasciitilde{} condition + covar1 + \ldots{} + covarN), there's also a selector to input the annotations columns desired on the output of the analysis. Finally, there's a selector to indicate the type of data that is being studied, whether is microarray or RNAseq. There's a selector to choose to do a surrogate variable analysis.

Once the analysis is performed a table with the results is displayed below the parameter selectors. The download button will prompt a system window to select where to store the shown table, it will save them as a \texttt{*.csv}.

If the analysis is being performed usging a pooled dataset, the shown table corresponds to all the pooled data.

\includegraphics{images/omics1.png}

\hypertarget{deseq}{%
\subsection{DESeq}\label{deseq}}

To be implemented.

\hypertarget{edger}{%
\subsection{edgeR}\label{edger}}

To be implemented.

\hypertarget{developers-guide}{%
\chapter{Developers Guide}\label{developers-guide}}

Along this section, documentation for future developers and maintainers of ShinyDataSHIELD is provided. It contains information about how the whole Shiny application is structured, all the different scripts that contains, flowcharts of the different files and information on how to extend the capabilities of ShinyDataSHIELD to new types of resources as well as new methodologies.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 0\tabcolsep) * \real{1.00}}@{}}
\toprule
❗ Observation \\
\midrule
\endhead
Please read this documentation with the actual source code on the side for easier understanding. \\
\bottomrule
\end{longtable}

\hypertarget{file-structure-of-shinydatashield}{%
\section{File structure of ShinyDataSHIELD}\label{file-structure-of-shinydatashield}}

Typically Shiny applications are contained in a single file or two files, since the typical structure of a Shiny application is to have a \texttt{server} function and a \texttt{ui} function that can be on the same file or split for larger applications. On ShinyDataSHIELD the \texttt{server} function has been split into different scripts where all of them contains the code of a certain block of the application. It has been done this way to not have a really long \texttt{server} file that is difficult to navigate and debug. There is no need to split the \texttt{ui} file into different scripts since it only contains the graphical declarations of the applications and is really easy to update and navigate.

The different scripts that compose the whole ShinyDataSHIELD are the following:

\begin{itemize}
\tightlist
\item
  \texttt{ui.R}
\item
  \texttt{server.R}, composed of the folowing scripts:

  \begin{itemize}
  \tightlist
  \item
    \texttt{connection.R}
  \item
    \texttt{descriptive\_stats.R}
  \item
    \texttt{download\_handlers.R}
  \item
    \texttt{genomics.R}
  \item
    \texttt{omics.R}
  \item
    \texttt{plot\_renders.R}
  \item
    \texttt{statistic\_models.R}
  \item
    \texttt{table\_renders.R}
  \item
    \texttt{table\_columns.R}
  \end{itemize}
\end{itemize}

The file \texttt{server.R} exists to source the different files and it also includes some small funcionalities.

Now a file per file explanation will be given with flowcharts (when needed), remarkable bits of code explanations and general remarks. Also, details on how to implement new functionalities will be given when needed.

\hypertarget{ui.r}{%
\subsection{\texorpdfstring{\texttt{ui.R}}{ui.R}}\label{ui.r}}

Inside this file there are all the declarations of how the graphical user interface (GUI) will look like.

First, it contains a declaration of all the libraries that have to be loaded for the application to run. The libraries are the following: \texttt{DSI,\ DSOpal,\ dsBaseClient,\ dsOmicsClient,\ shinydashboard,\ shiny,\ shinyalert,\ DT,\ data.table,\ shinyjs,\ shinyBS,\ shinycssloaders,\ shinyWidgets,\ stringr)}.

The next piece of code found

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{jscode }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}}
\StringTok{$(document).keyup(function(event) \{}
\StringTok{    if ($("\#password1").is(":focus") \&\& (event.keyCode == 13)) \{}
\StringTok{        $("\#connect\_server1").click();}
\StringTok{    \};}
\StringTok{    if ($("\#pat1").is(":focus") \&\& (event.keyCode == 13)) \{}
\StringTok{        $("\#connect\_server1").click();}
\StringTok{    \}}
\StringTok{\});}
\StringTok{\textquotesingle{}}
\end{Highlighting}
\end{Shaded}

Is a JavaScript declaration that reads as: When the \#password1 item (corresponds to the text input of the password on the data entry tab) is active (the user is writting in it) and the ``Intro'' key is pressed, trigger the \#connect\_server1 item (corresponds to the ``Connect'' button on the GUI). That provides the user the typical experience of inputting the login credentials and pressing ``Intro'' to log in.

It's important noting that this is only the declaration of a string with the code inside, to actually make use of it, there is the line 58 of this same file that actually implements it.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tags}\SpecialCharTok{$}\FunctionTok{head}\NormalTok{(tags}\SpecialCharTok{$}\FunctionTok{script}\NormalTok{(}\FunctionTok{HTML}\NormalTok{(jscode)))}
\end{Highlighting}
\end{Shaded}

Two more pieces of JavaScript and CSS are found

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{jscode\_tab }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{shinyjs.disableTab = function(name) \{}
\StringTok{  var tab = $(\textquotesingle{}.nav li a[data{-}value=\textquotesingle{} + name + \textquotesingle{}]\textquotesingle{});}
\StringTok{  tab.bind(\textquotesingle{}click.tab\textquotesingle{}, function(e) \{}
\StringTok{    e.preventDefault();}
\StringTok{    return false;}
\StringTok{  \});}
\StringTok{  tab.addClass(\textquotesingle{}disabled\textquotesingle{});}
\StringTok{\}}

\StringTok{shinyjs.enableTab = function(name) \{}
\StringTok{  var tab = $(\textquotesingle{}.nav li a[data{-}value=\textquotesingle{} + name + \textquotesingle{}]\textquotesingle{});}
\StringTok{  tab.unbind(\textquotesingle{}click.tab\textquotesingle{});}
\StringTok{  tab.removeClass(\textquotesingle{}disabled\textquotesingle{});}
\StringTok{\}}
\StringTok{"}

\NormalTok{css\_tab }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{.nav li a.disabled \{}
\StringTok{  background{-}color: \#aaa !important;}
\StringTok{  color: \#333 !important;}
\StringTok{  cursor: not{-}allowed !important;}
\StringTok{  border{-}color: \#aaa !important;}
\StringTok{\}"}
\end{Highlighting}
\end{Shaded}

The CSS is just for aesthetics, the JS however is to introduce the funcionality of enabling and disabling panels of the web application, this is used as \texttt{js\$disableTab()} and \texttt{js\$enableTab()} along the application. Those two scripts are integrated to the application when building the \texttt{dashboardBody} by using this

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{useShinyjs}\NormalTok{(),}
\FunctionTok{extendShinyjs}\NormalTok{(}\AttributeTok{text =}\NormalTok{ jscode\_tab, }\AttributeTok{functions =} \FunctionTok{c}\NormalTok{(}\StringTok{"enableTab"}\NormalTok{, }\StringTok{"disableTab"}\NormalTok{)),}
\FunctionTok{inlineCSS}\NormalTok{(css\_tab)}
\end{Highlighting}
\end{Shaded}

There are a some functions used in this file that are worth mentioning:

\begin{itemize}
\tightlist
\item
  \texttt{hidden()}: From the \texttt{shinyjs} library. The elements wrapped inside of this function will not be rendered by default, they have to be toggled from the server side. Example: A GUI element that needs to be displayed only when a certain condition is met.
\item
  \texttt{withSpinner()}: From the \texttt{shinycssloaders} library. The elements wrapped inside of this function will be displayed as a ``loading spinner'' when they are being processed. This is used to wrap figure displays. Example: A plot that is being rendered, it's better for the user experience to see a ``loading spinner'' so that it knows something is being processed rather than just staring at a blank screen waiting for something to happen.
\item
  \texttt{bsModal()}: From the \texttt{shinyBS} library. It's used to prompt pop-ups to the user. Example: By the click of a button you want to render a pop-up to the application with a figure of an histogram of a selected column of a table.
\item
  \texttt{conditionalPanel()}: From the \texttt{shiny} library. It is useful to display certain elements on the GUI regarding a condition is met or not, here is used to display the user / password fields or the personal access token (PAT) fields by checking the state of the selector. Note that the condition has to be written using JavaScript, that's why it looks like \texttt{"input.pat\_switch1\ ==\ true"} rather than the typical R Shiny \texttt{input\$pat\_switch1\ ==\ TRUE}.
\end{itemize}

In order to declare the elements when the user wants to add another server some R tricks are used, they are described and coded on the \protect\hyperlink{connection}{\texttt{connection.R}} file.

The rest of this file is your average Shiny functions and declarations, read the official \href{https://shiny.rstudio.com/reference/shiny/1.4.0/}{documentation} for any doubts. Please note that ShinyDataSHIELD uses \texttt{shinydashboard} to improve the looks and user experience, for any doubts regarding that please read it's \href{https://rstudio.github.io/shinydashboard/get_started.html}{documentation}.

\hypertarget{server.r}{%
\subsection{\texorpdfstring{\texttt{server.R}}{server.R}}\label{server.r}}

The server file is divided into the following blocks.

\begin{itemize}
\tightlist
\item
  Declaration of reactiveValues: As a code practice measure, all the variables that have to be used in different parts of the code (Example: Table that contains the information about the loaded resources, has to be written when loading the data and afterwards to check whether a resource has been loaded or not) are reactive values. The only occassions where there are ``regular'' variables are inside functions that use variables as placeholders to be used only inside of that function (Example: Storing the results of a middle ground operation to be later used inside the same function to perform the final analysis, whose results will be saved on a reactive value variable). Developers used to lower level languages can see this as \texttt{public} and \texttt{private} variables.
\item
  Sourcing of scripts: Sourcing all the different scripts that actually make up \texttt{server.R}. As said before this is done this way to have a more structured application where each script takes care of a certain block of the application.
\item
  Disabling of all the tabs except the server connector: By default all the tabs are visible on Shiny, in order to provide a good user experience all are disabled at the launch of the application using \texttt{js\$disableTab()}, once tables or resources are loaded into the study servers tabs are enabled (only the ones that makes sense, if the user loads a Table, only the tabs to interacts with tables will be enabled).
\item
  Function declaration: Declaration of a function that given a column of a data table will truncate the decimal places to 4, it's used when rendering tables to not have tables with 9 decimals that look hideous.
\item
  Functions to manage the ``Connected'' / ``No connection'' display. It's a bunch of logic and CSS to just control a small element of the GUI. Basically if the variable \texttt{connection\$active} is \texttt{TRUE} the GUI will show ``Connected'' next to a green dot with a ``Disconnect'' button, otherwise it will display ``No connection'' next to a red dot. When the button ``Disconnect'' is pressed, the function to log out of the server is triggered and the \texttt{connection\$active} variable is set to false.
\item
  Stop function: This delcaration is left for future developers. When having trouble on a certain spot, add a stop button using \texttt{actionButton("stop",\ "stop")}, press it on the GUI to stop the execution and perform the required debugging.
\end{itemize}

\includegraphics{images/dev1.png}

\includegraphics{images/dev2.png}

The scripts sourced for by the \texttt{server.R} are the following:

\hypertarget{connection}{%
\subsubsection{\texorpdfstring{\texttt{connection.R}}{connection.R}}\label{connection}}

This is probably the most important script of the whole application, as it's the one that is responsible for loading the data in order to ensure that the application capabilities can be extended in the future painlessly (modular).

Inside this script there are five different sections that are triggered by different actions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Creation of GUI for the new server tabs
\item
  Creation of \texttt{observeEvents} for all the different server tab elements.

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    URL builder to display selected items on a browser
  \item
    Connection to the server to obtain the projects and resources. Triggered by the button with label ``connect\_server''.
  \item
    Get tables / resources from the selected project. Triggered everytime the selector with label ``project\_selected'' is changed.
  \item
    Add a study. Triggered by the button with label ``add\_server''.
  \end{enumerate}
\item
  Remove a server tab. Triggered by the button with label ``remove''.
\item
  Remove a study item Triggered by the button with label ``remove\_item''.
\item
  Load the selected studies to the study servers. Triggered by the button with label ``connect\_selected''.
\end{enumerate}

The first element to explain is the creation of the new server tabs (Point 1, \texttt{observeEvent(input\$add,\ \{\})}). It's just a matter of noting two things to understand it easily, 1) The use of a reactive value \texttt{tabIndex()} which returns a integer (initialized at \texttt{1}), this integer corresponds to the tab being created (hence it's updated at the top of the call); 2) The rest of the call is an \texttt{appendTab()} that adds a new tab on the element id \texttt{"tabset1"} with the exact structure of \texttt{ui.R} but changing the element IDs using the reactive value so that all the buttons/input fields are numbered according to the tab they are located on. When removing a server tab (\texttt{observeEvent(input\$remove,\ \{\})}) the tab itself is removed using \texttt{removeTab()} and the reactive value is actualized.

The creation of \texttt{observeEvents} for all the different server tab elements (Subitems of point 2) is done using a small trick. \texttt{max\_servers} number of \texttt{observeEvents} are created (using \texttt{lapply}) for the different functionalities so that all the server tabs are functional, this integer variable is defined on the script \texttt{server.R}, if more servers than the default (10) are required just update the definition of the variable and relaunch the application.

The last part of the script, loads all the selected tables and resources to the selected study servers. It does everything needed to each particular type of resource, that means converting them to R objects or to tables depending on what they are.

When loading the selected resources or tables into the study servers, the table \texttt{available\_tables} is created. The name is a little bit confusing since it actually contains the information about tables and resources, the developer apologizes as this variable was set at the beginning of the development and has not been updated. Nevertheless, it's an important variable of the application, the structure of this table is the following.

\begin{longtable}[]{@{}ll@{}}
\toprule
Column & Description \\
\midrule
\endhead
name & Name of the object (\texttt{project.name}) \\
server\_index & Index of the study server that contains the table/resource \\
server & Name of the study server \\
type\_resource & Type of the resource \\
\bottomrule
\end{longtable}

The Opal server can host different types of resources, to name a few there are \texttt{ExpressionSet}, \texttt{RangedSummarizedExperiment} and \texttt{SQLResourceClient}. Each type of resource needs a special treatment to be used, for example \texttt{SQLResourceClient} resources are plain tables, so they need to be converted to tables on the study server to use them. Currently the following resource types are supported by ShinyDataSHIELD.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.18}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.61}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.21}}@{}}
\toprule
Resource type & Treatment & Name of the resource type on \texttt{available\_tables} \\
\midrule
\endhead
TidyFileResourceClient, SQLResourceClient & - \texttt{as.resource.data.frame(resource)}- Append \texttt{.t} to the name & \texttt{table} \\
SshResourceClient & Append \texttt{.r} to the name & \texttt{ssh} \\
GdsGenotypeReader & - \texttt{as.resource.object(resource)} - Append \texttt{.r} to the name & \texttt{r\_obj\_vcf} \\
ExpressionSet & - \texttt{as.resource.object(resource)}- Append \texttt{.r} to the name & \texttt{r\_obj\_eset} \\
RangedSummarizedExperiment & - \texttt{as.resource.object(resource)}- Append \texttt{.r} to the name & \texttt{r\_obj\_rse} \\
Any other resource type & - \texttt{as.resource.object(resource)}- Append \texttt{.r} to the name & \texttt{r\_obj} \\
\bottomrule
\end{longtable}

\texttt{.r} and \texttt{.t} are appended to the resources to allow a resource and a table on the same project to have the same names and not crash the Shiny application.

Now, let's look at some examples to add new resource types on the \texttt{connection.R} file. There are different cases for the treatment that the new resource requires.

\begin{itemize}
\tightlist
\item
  Resources that just need to be loaded with no further action performed to them (same treatment as SSH connections). Add another \texttt{else\ if} statement after line 303. Example: New resource called \texttt{Simple\_resource}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (}\StringTok{"Simple\_resource"} \SpecialCharTok{\%in\%}\NormalTok{ resource\_type)\{}
            \CommentTok{\# Update available\_tables list with the new resource type name}
\NormalTok{lists}\SpecialCharTok{$}\NormalTok{available\_tables }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(lists}\SpecialCharTok{$}\NormalTok{available\_tables, }\FunctionTok{c}\NormalTok{(}\AttributeTok{name =}\NormalTok{ name, }\AttributeTok{server\_index =}\NormalTok{ server\_index,}
                                                                      \AttributeTok{server =}\NormalTok{ resources}\SpecialCharTok{$}\NormalTok{study\_server[i], }\AttributeTok{type\_resource =} \StringTok{"Simple\_resource"}\NormalTok{))}
\NormalTok{          \}}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Resources that need to be converted into R objects (\texttt{datashield.assign.expr(conns,\ symbol\ =\ "methy",\ expr\ =\ quote(as.resource.object(res)))}) and nothing else. Will work out of the box (the \texttt{type\_resource} column of the \texttt{lists\$available\_tables} table will read \texttt{r\_obj}).
\item
  Resources that need to be converted into R objects (\texttt{datashield.assign.expr(conns,\ symbol\ =\ "methy",\ expr\ =\ quote(as.resource.object(res)))}) and be further processed. Add another \texttt{else\ if} statement after line 320. Example: A new type of resource called \texttt{special\_resource} that contains some variable names that are desired to be saved on a variable to feed a list on the GUI.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{(}\StringTok{"special\_resource"} \SpecialCharTok{\%in\%}\NormalTok{ resource\_type) \{}
              \CommentTok{\# Update available\_tables list with the new resource type name}
\NormalTok{  lists}\SpecialCharTok{$}\NormalTok{available\_tables }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(lists}\SpecialCharTok{$}\NormalTok{available\_tables, }\FunctionTok{c}\NormalTok{(}\AttributeTok{name =}\NormalTok{ name, }\AttributeTok{server\_index =}\NormalTok{ server\_index,}
                                                                        \AttributeTok{server =}\NormalTok{ resources}\SpecialCharTok{$}\NormalTok{study\_server[i], }\AttributeTok{type\_resource =} \StringTok{"special\_resource"}\NormalTok{))}
              \CommentTok{\# Perform the needed actions for this resource}
\NormalTok{              [...]}
\NormalTok{            \}}
\end{Highlighting}
\end{Shaded}

Finally, once all the connections have been successful, and all the selected tables and resources are loaded, the tabs that make use of the loaded objects are enabled by using (table examples)

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if}\NormalTok{(}\FunctionTok{any}\NormalTok{(}\FunctionTok{unique}\NormalTok{(lists}\SpecialCharTok{$}\NormalTok{available\_tables}\SpecialCharTok{$}\NormalTok{type\_resource) }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"table"}\NormalTok{))) \{}
        \FunctionTok{show}\NormalTok{(}\AttributeTok{selector =} \StringTok{"ul li:eq(2)"}\NormalTok{)}
\NormalTok{      \}}
\end{Highlighting}
\end{Shaded}

There are many \texttt{if} that checks for type of resources and enables tabs if present, on the previous example the second tab \texttt{ul\ li:eq(2)} (there is no way of refering them by ID as far as I know to perform this action) is enabled because it contains a module that works with tables.

If a new type of resource is implemented, add after line 353 (tab 10 is just as example)

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if}\NormalTok{(}\FunctionTok{any}\NormalTok{(}\FunctionTok{unique}\NormalTok{(lists}\SpecialCharTok{$}\NormalTok{available\_tables}\SpecialCharTok{$}\NormalTok{type\_resource) }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"new\_resource"}\NormalTok{))) \{}
        \FunctionTok{show}\NormalTok{(}\AttributeTok{selector =} \StringTok{"ul li:eq(10)"}\NormalTok{)}
\NormalTok{      \}}
\end{Highlighting}
\end{Shaded}

Also update this part if a new module is added, make sure to enable the tab only when the resources that the module use are present on the \texttt{lists\$available\_tables}.

\hypertarget{structure-of-the-modules}{%
\subsection{Structure of the modules}\label{structure-of-the-modules}}

A common structure is followed for all the different modules, this refers to the general structure of \texttt{descriptive\_stats.R}, \texttt{statistics\_models.R}, \texttt{genomics.R}, \texttt{omics.R} and \texttt{table\_columns.R}.

Before describing the internal structure of the modules, let's briefly describe the GUI structure, which is also common between them. The tabs are filled with a tab box, the first element is always a table with the available tables / resources for that module. For example, the Omics module only displays the resources of type RSE or eSet. The other tabs are disabled by default and can only be accessed once the user has selected which resource to use. Now let's talk about how to accomplish all of this.

At the beginning of all the modules there is an \texttt{observeEvent} that is triggered when the user selects an item from the table. The structure of this is the following

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{observeEvent}\NormalTok{(input}\SpecialCharTok{$}\NormalTok{table, \{}
  \ControlFlowTok{if}\NormalTok{(}\FunctionTok{length}\NormalTok{(input}\SpecialCharTok{$}\NormalTok{table\_rows\_selected) }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{)\{ }\CommentTok{\# Check if the user has selected any row}
\NormalTok{    different\_study\_server }\OtherTok{\textless{}{-}} \ConstantTok{TRUE} \CommentTok{\# On this example we are checking that everything selected is on different study servers}
\NormalTok{    same\_cols }\OtherTok{\textless{}{-}} \ConstantTok{TRUE} \CommentTok{\# On this example we are checking tables to be pooled, so we are checking they have the same columns}
    \ControlFlowTok{if}\NormalTok{(}\FunctionTok{length}\NormalTok{(input}\SpecialCharTok{$}\NormalTok{table\_rows\_selected) }\SpecialCharTok{\textgreater{}} \DecValTok{1}\NormalTok{)\{ }\CommentTok{\# If more than one table is selected the checks have to be performed, otherwise there is no need to check for same cols or different study servers}
\NormalTok{      same\_cols }\OtherTok{\textless{}{-}} \FunctionTok{all}\NormalTok{(}\FunctionTok{lapply}\NormalTok{(input}\SpecialCharTok{$}\NormalTok{tqble\_rows\_selected, }\ControlFlowTok{function}\NormalTok{(i)\{}
\NormalTok{        res}\OtherTok{\textless{}{-}}\FunctionTok{all}\NormalTok{(}\FunctionTok{match}\NormalTok{(lists}\SpecialCharTok{$}\NormalTok{resource\_variables[[}\FunctionTok{as.character}\NormalTok{(lists}\SpecialCharTok{$}\NormalTok{available\_tables[type\_resource }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"table"}\NormalTok{)][i,}\DecValTok{1}\NormalTok{])]], }
\NormalTok{                       lists}\SpecialCharTok{$}\NormalTok{resource\_variables[[}\FunctionTok{as.character}\NormalTok{(lists}\SpecialCharTok{$}\NormalTok{available\_tables[type\_resource }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"table"}\NormalTok{)][}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{])]]))}
        \ControlFlowTok{if}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(res))\{}\ConstantTok{FALSE}\NormalTok{\} }\ControlFlowTok{else}\NormalTok{\{res\}}
\NormalTok{      \}))}
\NormalTok{      different\_study\_server }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(}\FunctionTok{unique}\NormalTok{(lists}\SpecialCharTok{$}\NormalTok{available\_tables[input}\SpecialCharTok{$}\NormalTok{table\_rows\_selected,}\DecValTok{3}\NormalTok{])) }\SpecialCharTok{==}
        \FunctionTok{length}\NormalTok{(input}\SpecialCharTok{$}\NormalTok{table\_rows\_selected) }
\NormalTok{    \}}
    \ControlFlowTok{if}\NormalTok{(same\_cols }\SpecialCharTok{\&}\NormalTok{ different\_study\_server)\{ }\CommentTok{\# If both tests are OK, remove the "resource\_lim" object from the study servers}
      \FunctionTok{datashield.rm}\NormalTok{(connection}\SpecialCharTok{$}\NormalTok{conns, }\StringTok{"resource\_lim"}\NormalTok{)}
      \ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in}\NormalTok{ input}\SpecialCharTok{$}\NormalTok{table\_rows\_selected)\{}
\NormalTok{        lists}\SpecialCharTok{$}\NormalTok{available\_tables[type\_resource }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"table"}\NormalTok{)][i,}\DecValTok{2}\NormalTok{]}
        \CommentTok{\# Then assign the selected tables to a new variable on the study servers called "resource\_lim", this is the variable that all the other funcionalities of the module will refer to when performing analysis}
        \FunctionTok{datashield.assign.expr}\NormalTok{(connection}\SpecialCharTok{$}\NormalTok{conns[}\FunctionTok{as.numeric}\NormalTok{(lists}\SpecialCharTok{$}\NormalTok{available\_tables[type\_resource }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"table"}\NormalTok{)][i,}\DecValTok{2}\NormalTok{])], }\StringTok{"resource\_lim"}\NormalTok{, }\FunctionTok{as.symbol}\NormalTok{(}\FunctionTok{as.character}\NormalTok{(lists}\SpecialCharTok{$}\NormalTok{available\_tables[type\_resource }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"table"}\NormalTok{)][i,}\DecValTok{1}\NormalTok{])))}
\NormalTok{      \}}
      \CommentTok{\# Enable the analysis tab and update the GUI to display it}
\NormalTok{      js}\SpecialCharTok{$}\FunctionTok{enableTab}\NormalTok{(}\StringTok{"tab\_of\_analysis"}\NormalTok{)}
      \FunctionTok{updateTabsetPanel}\NormalTok{(session, }\StringTok{"id"}\NormalTok{,}
                        \AttributeTok{selected =} \StringTok{"tab\_of\_analysis"}\NormalTok{)}
\NormalTok{    \}}
    \ControlFlowTok{else}\NormalTok{\{ }\CommentTok{\# If the tests fail, display an error message}
      \FunctionTok{shinyalert}\NormalTok{(}\StringTok{"Oops!"}\NormalTok{, }
                 \ControlFlowTok{if}\NormalTok{(}\SpecialCharTok{!}\NormalTok{same\_cols)\{}
                   \StringTok{"Selected resources do not share the same columns, can\textquotesingle{}t pool unequal resources"}
\NormalTok{                 \}}\ControlFlowTok{else}\NormalTok{\{}
                   \StringTok{"Selected resources are not on different study servers, can\textquotesingle{}t pool resources on the same study server."}
\NormalTok{                 \}}
\NormalTok{                 , }\AttributeTok{type =} \StringTok{"error"}\NormalTok{)}
      \CommentTok{\# Make sure analysis tabs are disabled and the GUI shows the selection tab, this is important to do because if the user first selects a valid table and then an invalid combination, we want to make sure that the user has no longer access to the analysis tab}
\NormalTok{      js}\SpecialCharTok{$}\FunctionTok{disableTab}\NormalTok{(}\StringTok{"tab\_of\_analysis"}\NormalTok{)}
      \FunctionTok{updateTabsetPanel}\NormalTok{(session, }\StringTok{"id"}\NormalTok{,}
                        \AttributeTok{selected =} \StringTok{"table\_selection"}\NormalTok{)}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

This example can be extended to the developers needs, but as a structure example is more than enough. Please read the source code for the available modules if extra examples are needed.

The body of the modules correspond to whatever is needed on that module, let that be some \texttt{observeEvent} for buttons of the analysis tab, some \texttt{renderUI} for dynamic selectors or anything other that the module needs.

The bottom of the modules is also shared, they contain an \texttt{observe} clause that is triggered when the tab is selected, it has the following structure

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{observe}\NormalTok{(\{}
  \ControlFlowTok{if}\NormalTok{(input}\SpecialCharTok{$}\NormalTok{tabs }\SpecialCharTok{==} \StringTok{"id"}\NormalTok{) \{ }\CommentTok{\# The ID here corresponds to the tabname declare on the ui.R ; tabItem(tabName = "ID", ....... }
\NormalTok{    tables\_available }\OtherTok{\textless{}{-}}\NormalTok{ lists}\SpecialCharTok{$}\NormalTok{available\_tables[type\_resource }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"table"}\NormalTok{)] }\CommentTok{\# Input here the type\_resource that this module uses, so only those are displayed}
    \ControlFlowTok{if}\NormalTok{(}\FunctionTok{length}\NormalTok{(lists}\SpecialCharTok{$}\NormalTok{resource\_variables) }\SpecialCharTok{==} \DecValTok{0}\NormalTok{)\{}
      \FunctionTok{withProgress}\NormalTok{(}\AttributeTok{message =} \StringTok{"Reading column names from available tables"}\NormalTok{, }\AttributeTok{value =} \DecValTok{0}\NormalTok{, \{}
        \ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(tables\_available))\{ }\CommentTok{\# In this example we are reading table columns so that when the user selects from this table, we can automatically check if the columns are shared when trying to pool tables, this is done on the header of the module, that we have just seen}
\NormalTok{          lists}\SpecialCharTok{$}\NormalTok{table\_columns[[}\FunctionTok{as.character}\NormalTok{(tables\_available[i,}\DecValTok{1}\NormalTok{])]] }\OtherTok{\textless{}{-}} \FunctionTok{ds.colnames}\NormalTok{(}\FunctionTok{as.character}\NormalTok{(tables\_available[i,}\DecValTok{1}\NormalTok{]), }\AttributeTok{datasources =}\NormalTok{ connection}\SpecialCharTok{$}\NormalTok{conns[}\FunctionTok{as.numeric}\NormalTok{(tables\_available[i,}\DecValTok{2}\NormalTok{])])[[}\DecValTok{1}\NormalTok{]]}
          \FunctionTok{incProgress}\NormalTok{(i}\SpecialCharTok{/}\FunctionTok{nrow}\NormalTok{(tables\_available))}
\NormalTok{        \}}
\NormalTok{      \})}
\NormalTok{    \}}
    \CommentTok{\# Finally we render the table with the available tables for this module so the user can select which ones to use, of course this needs to be completed on the table\_renders.R (following chunk has an example)}
\NormalTok{    output}\SpecialCharTok{$}\NormalTok{available\_tables\_sm }\OtherTok{\textless{}{-}} \FunctionTok{renderUI}\NormalTok{(\{}
      \FunctionTok{dataTableOutput}\NormalTok{(}\StringTok{"available\_tables"}\NormalTok{)}
\NormalTok{    \})}
\NormalTok{  \}}
\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

Example of the code for the table\_render.R regarding the selection table

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{output}\SpecialCharTok{$}\NormalTok{available\_tables }\OtherTok{\textless{}{-}} \FunctionTok{renderDT}\NormalTok{(}
\NormalTok{  lists}\SpecialCharTok{$}\NormalTok{available\_tables[type\_resource }\SpecialCharTok{==} \StringTok{"table"}\NormalTok{], }\AttributeTok{options=}\FunctionTok{list}\NormalTok{(}\AttributeTok{columnDefs =} \FunctionTok{list}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{visible=}\ConstantTok{FALSE}\NormalTok{, }\AttributeTok{targets=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{))),}
                                                                 \AttributeTok{paging =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{searching =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now let's take a look at the scripts that are used by all the modules, their use is to render tables, figures and handle the downloads (figures + table downloads)

\hypertarget{table_renders.r}{%
\subsubsection{\texorpdfstring{\texttt{table\_renders.R}}{table\_renders.R}}\label{table_renders.r}}

This script creates the displays of all the tables of ShinyDataSHIELD, it uses the \texttt{DT} package to do so. Besides the \texttt{descriptive\_summary} table, all the other tables just render results from other functions.

There are some things to point of this script:

\begin{itemize}
\tightlist
\item
  As can be seen in \texttt{descriptive\_summary} table, you can actually perform operations inside of a \texttt{renderDT} function and display the result of them.
\item
  The most used options for the tables aesthetics are the following
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{options}\OtherTok{=}\FunctionTok{list}\NormalTok{(}\AttributeTok{columnDefs =} \FunctionTok{list}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{visible=}\ConstantTok{FALSE}\NormalTok{, }\AttributeTok{targets=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{))),}
                                          \AttributeTok{paging =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{searching =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This prevents the \texttt{rownames} column to be displayed (usually it just contains the numeration of rows 1\ldots N, be aware sometimes it's of interest to see this column) and eliminates the paging and searching functionalities of the table. For small tables it makes sense to not show that but on big tables those options are set to \texttt{TRUE}, as it's very useful to have a search box on them.

\begin{itemize}
\tightlist
\item
  The tables that display numerical columns (mixed or not with non-numerical columns) are actually passed through the \texttt{format\_num} function (defined on \texttt{server.R}) so the displayed table has only four decimals but the actual table (the one that can be saved) has all the decimals. This is done using the following code
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{as.data.table}\NormalTok{(}\FunctionTok{lapply}\NormalTok{(}\FunctionTok{as.data.table}\NormalTok{(vcf\_results}\SpecialCharTok{$}\NormalTok{result\_table\_gwas}\SpecialCharTok{$}\NormalTok{server1), format\_num))}
\end{Highlighting}
\end{Shaded}

This will pass each column to the function and if it's numerical the decimals will be cut to 4.

\begin{itemize}
\tightlist
\item
  The table output structure of the LIMMA results look different than the others, this is because when performing a LIMMA with pooled resources it returns one table for each study, what is being done is just binding them to display to the user all the obtained results.
\end{itemize}

There is a concrete render that needs a special mention on this documentation, that is the \texttt{column\_types\_table}, which uses the CellEdit JavaScript plugin to enable drop down menus when editing a table. Let's see what is being done

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tab }\OtherTok{\textless{}{-}} \FunctionTok{datatable}\NormalTok{(}
\NormalTok{      table\_to\_be\_modified, }\AttributeTok{editable =} \StringTok{"cell"}\NormalTok{, }\AttributeTok{callback =}  \CommentTok{\# The callback needs to be updated to include the JS custom code}
        \FunctionTok{JS}\NormalTok{(}
          \StringTok{"function onUpdate(updatedCell, updatedRow, oldValue)\{"}\NormalTok{,}
          \StringTok{"Shiny.onInputChange(\textquotesingle{}jsValue\textquotesingle{}, [updatedCell.index(), updatedCell.data()]);"}\NormalTok{, }\CommentTok{\# The results to actually update the table\_to\_be\_modified on the module script will be retrieved by a observeEvent(input$jsValue, \{ ; change jsValue each time this approach is used to avoid collisions}
          \StringTok{"\}"}\NormalTok{,}
          \StringTok{"table.MakeCellsEditable(\{"}\NormalTok{,}
          \StringTok{"  onUpdate: onUpdate,"}\NormalTok{,}
          \StringTok{"  inputCss: \textquotesingle{}my{-}input{-}class\textquotesingle{},"}\NormalTok{,}
          \StringTok{"  columns: [2],"}\NormalTok{,}
          \StringTok{"  confirmationButton: \{"}\NormalTok{,}
          \StringTok{"    confirmCss: \textquotesingle{}my{-}confirm{-}class\textquotesingle{},"}\NormalTok{,}
          \StringTok{"    cancelCss: \textquotesingle{}my{-}cancel{-}class\textquotesingle{}"}\NormalTok{,}
          \StringTok{"  \},"}\NormalTok{,}
          \StringTok{"  inputTypes: ["}\NormalTok{,}
          \StringTok{"    \{"}\NormalTok{,}
          \StringTok{"      column: 2,"}\NormalTok{,}
          \StringTok{"      type: \textquotesingle{}list\textquotesingle{},"}\NormalTok{,}
          \StringTok{"      options: ["}\NormalTok{,}
          \StringTok{"        \{value: \textquotesingle{}numeric\textquotesingle{}, display: \textquotesingle{}numeric\textquotesingle{}\},"}\NormalTok{, }\CommentTok{\# Update this lines to declare the options of the dropdown}
          \StringTok{"        \{value: \textquotesingle{}factor\textquotesingle{},      display: \textquotesingle{}factor\textquotesingle{}\},"}\NormalTok{,}
          \StringTok{"        \{value: \textquotesingle{}character\textquotesingle{},    display: \textquotesingle{}character\textquotesingle{}\}"}\NormalTok{,}
          \StringTok{"      ]"}\NormalTok{,}
          \StringTok{"    \}"}\NormalTok{,}
          \StringTok{"  ]"}\NormalTok{,}
          \StringTok{"\});"}\NormalTok{),}
      \AttributeTok{options =} \FunctionTok{list}\NormalTok{(}\AttributeTok{pageLength =} \FunctionTok{nrow}\NormalTok{(table\_to\_be\_modified))}
\NormalTok{    )}
\NormalTok{    path }\OtherTok{\textless{}{-}} \StringTok{"../../www/"} \CommentTok{\# folder containing the files dataTables.cellEdit.js}
    \CommentTok{\# and dataTables.cellEdit.css, they are already included on ShinyDataSHIELD, so there is no need to worry about that}
\NormalTok{    dep }\OtherTok{\textless{}{-}}\NormalTok{ htmltools}\SpecialCharTok{::}\FunctionTok{htmlDependency}\NormalTok{(}
      \StringTok{"CellEdit"}\NormalTok{, }\StringTok{"1.0.19"}\NormalTok{, path,}
      \AttributeTok{script =} \StringTok{"dataTables.cellEdit.js"}\NormalTok{, }\AttributeTok{stylesheet =} \StringTok{"dataTables.cellEdit.css"}\NormalTok{)}
\NormalTok{    tab}\SpecialCharTok{$}\NormalTok{dependencies }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(tab}\SpecialCharTok{$}\NormalTok{dependencies, }\FunctionTok{list}\NormalTok{(dep))}
\end{Highlighting}
\end{Shaded}

Example of what to include on the module script to update the table

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{proxy }\OtherTok{=} \FunctionTok{dataTableProxy}\NormalTok{(}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{) }\CommentTok{\# No need to change this}
\FunctionTok{observeEvent}\NormalTok{(input}\SpecialCharTok{$}\NormalTok{jsValue, \{ }\CommentTok{\# As stated above, the trigger is actually the value defined on the callback, we can retrieve the row, column and value from that object}
\NormalTok{  change }\OtherTok{\textless{}{-}} \FunctionTok{data.table}\NormalTok{(input}\SpecialCharTok{$}\NormalTok{jsValue)}
\NormalTok{  row }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(change[}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{]) }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{  column }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(change[}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{])}
\NormalTok{  value }\OtherTok{\textless{}{-}} \FunctionTok{as.character}\NormalTok{(change[}\DecValTok{4}\NormalTok{,}\DecValTok{1}\NormalTok{])}
  
\NormalTok{  table\_to\_be\_modified[row, column] }\OtherTok{\textless{}\textless{}{-}}\NormalTok{ value}
  \FunctionTok{replaceData}\NormalTok{(proxy, table\_to\_be\_modified, }\AttributeTok{resetPaging =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{plot_renders.r}{%
\subsubsection{\texorpdfstring{\texttt{plot\_renders.R}}{plot\_renders.R}}\label{plot_renders.r}}

There are two types of plots on ShinyDataSHIELD, the ones created with the base function \href{https://www.rdocumentation.org/packages/graphics/versions/3.6.2/topics/plot}{plot} and the ones created with the \href{https://ggplot2.tidyverse.org/}{ggplot} library. In order to later recover the plots to download them, they actually have a different structure.

\begin{itemize}
\tightlist
\item
  Base plot structure:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{output}\SpecialCharTok{$}\NormalTok{random\_plot }\OtherTok{\textless{}{-}} \FunctionTok{renderPlot}\NormalTok{(\{}
\NormalTok{  plots}\SpecialCharTok{$}\NormalTok{random\_plot }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{()\{}
    \FunctionTok{function\_that\_generates\_the\_plot\_using\_base\_package}\NormalTok{(arguments)}
\NormalTok{  \}}
\NormalTok{  plots}\SpecialCharTok{$}\FunctionTok{random\_plot}\NormalTok{()}
\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

For the base plots, a function is declared that returns the plot and is called to generate the plot to the GUI.

\begin{itemize}
\tightlist
\item
  Ggplot structure:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{output}\SpecialCharTok{$}\NormalTok{manhattan }\OtherTok{\textless{}{-}} \FunctionTok{renderPlot}\NormalTok{(\{}
\NormalTok{  plots}\SpecialCharTok{$}\NormalTok{ggplot }\OtherTok{\textless{}{-}} \FunctionTok{function\_that\_generates\_the\_plot\_using\_ggplot2\_package}\NormalTok{(arguments)}
\NormalTok{  plots}\SpecialCharTok{$}\NormalTok{ggplot}
\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

In this case the plot is saved, ggplot will generate a plot variable that can be called to render the plot.

On this script there are two plots that are inside a \texttt{renderCachedPlot} function instead of a \texttt{renderPlot} because they take really long to calculate and it's better to cache them.

Inside of the \texttt{renderPlot} function some other code can be put, such as toggles to GUI elements or \texttt{tryCatch()} functions.

\hypertarget{download_handlers.r}{%
\subsubsection{\texorpdfstring{\texttt{download\_handlers.R}}{download\_handlers.R}}\label{download_handlers.r}}

In this script everything related to downloading plots and tables is found. There are basically three types of structures

\begin{itemize}
\tightlist
\item
  Table downloader: To download a \texttt{*csv}. Structure:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{output}\SpecialCharTok{$}\NormalTok{table\_download }\OtherTok{\textless{}{-}} \FunctionTok{downloadHandler}\NormalTok{(}
  \AttributeTok{filename =} \StringTok{"table.csv"}\NormalTok{,}
  \AttributeTok{content =} \ControlFlowTok{function}\NormalTok{(file) \{}
    \FunctionTok{write.csv}\NormalTok{(}
\NormalTok{      variable\_that\_contains\_table}
\NormalTok{      , file, }\AttributeTok{row.names =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The \texttt{row.names\ =\ FALSE} argument may not be needed in tables where the row names are important.

\begin{itemize}
\tightlist
\item
  Base plot downloader: To download a \texttt{*.png}. Structure:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{output}\SpecialCharTok{$}\NormalTok{base\_plot\_download }\OtherTok{\textless{}{-}} \FunctionTok{downloadHandler}\NormalTok{(}
  \AttributeTok{filename =} \StringTok{"base\_plot.png"}\NormalTok{,}
  \AttributeTok{content =} \ControlFlowTok{function}\NormalTok{(file) \{}
    \FunctionTok{png}\NormalTok{(}\AttributeTok{file =}\NormalTok{ file)}
\NormalTok{    plots}\SpecialCharTok{$}\FunctionTok{base\_plot}\NormalTok{()}
    \FunctionTok{dev.off}\NormalTok{()}
\NormalTok{  \}}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Basically this calls the previously declared function and captures the plot into a \texttt{*.png}.

\begin{itemize}
\tightlist
\item
  GGplot downloader: To download a \texttt{*.png}. Structure:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{output}\SpecialCharTok{$}\NormalTok{ggplot\_download }\OtherTok{\textless{}{-}} \FunctionTok{downloadHandler}\NormalTok{(}
  \AttributeTok{filename =} \StringTok{"ggplot.png"}\NormalTok{,}
  \AttributeTok{content =} \ControlFlowTok{function}\NormalTok{(file) \{}
    \FunctionTok{ggsave}\NormalTok{(file, }\AttributeTok{plot =} \FunctionTok{last\_plot}\NormalTok{())}
\NormalTok{  \}}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

When using ggplot, the function \texttt{last\_plot()} renders the last plot rendered by ggplot. This only has one inconvenient, that is when you are downloading a plot that takes a while to render, the application doesn't show the save window dialog until it has rendered again. This should be addressed in the future as it really halters the user experience.

\hypertarget{how-to-add-a-new-block}{%
\subsection{How to add a new block}\label{how-to-add-a-new-block}}

To add a new block to ShinyDataSHIELD, the developer has to create a new \texttt{*.R} script inside the \texttt{inst/shinyApp/} folder of the project and give it a descriprive name of the function that it will perform.

So the Shiny application actually sees it, the \texttt{server.R} needs to be updated and source the new file. Example: New block called \texttt{new\_analysis.R}, the update to the \texttt{server.R} will be

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{source}\NormalTok{(}\StringTok{"new\_analysis.R"}\NormalTok{, }\AttributeTok{local =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Afterwards, the \texttt{ui.R} can be updated by defining how the new block will be presented to the user. The \texttt{sidebarMenu} function needs to be updated so that the new tab appears on the sidebar of the application, follow the structure of the other tabs. Afterwards update the \texttt{dashboardBody} function by defining all the different elements of the new tab, follow the structure of the other available tabs to follow the general design lines, all the functions that need to be used here are standard Shiny functions mostly and there's plenty of documentation and examples available online, when in doubt just try to copy an already implemented structure.

Now the user can focus on the types of files that will feed this new block, if it's a table there's no need to worry, if it's a resource that is not implemented the \texttt{connection.R} needs to be updated. Read the above documentation for guidance on the changes that need to be done for new resources types.

Once the GUI is setup and the table / resource that this block will use is setup, the backend for this block can be built on the \texttt{new\_analysis.R} file. Include on that file all the required \texttt{renderUI()} functions and steps to process the file and analyze it. Probably a new variable will be required to hold the results, update the \texttt{server.R} header and include a new \texttt{reactiveValues()} declaration for the new block.

If the new block requires to display tables or figures, update the \texttt{table\_renders.R} and \texttt{plot\_renders.R} following the given examples on their sections of the documentation. Make sure to include the download buttons for them on the \texttt{download\_handlers.R}.

If there is some part of the code that takes some time to process, there's the option of wrapping it inside the \texttt{withProgress()} function in order to display a loading annimation to the GUI to alert the user that something is being processed.

Make sure to include the custom implementation of the header and footer functions for the module that have been presented before.

When developing a new block there will probably be many problems occurring, in order to debug a Shiny application there is the \texttt{browser()} function, if the developer is getting some sort of error at X line of the script, just write \texttt{browser()} on the line adobe of the error, the execution will be stopped at that point and the developer can interact with all the available variables of the environment through the RStudio console, usually running the line that is giving an error on the console will provide enough information to kill the bug. If the line breaking is a function call it is advisable to type the variables that are being passed into the function on the console, that way the developer can see what exactly is being passed and can see that some argument is \texttt{NULL} when it shouldn't or it's a character when it should be a number, those are quite common problems.

When a new block is developed and integrated into ShinyDataSHIELD, please conclude it by updating this documentation and the user guide with a brief explanation of the new block and some remarks of the most interesting bits of it.

  \bibliography{book.bib,packages.bib}

\end{document}
